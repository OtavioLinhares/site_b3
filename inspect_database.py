"""
Fase 0: Inspe√ß√£o de Qualidade de Dados

Objetivo: Auditar data/processed/cvm_financials_history.csv e price_history.json
          para identificar dados faltantes, incoerentes ou inv√°lidos
"""

import json
import pandas as pd
from collections import defaultdict
from pathlib import Path


class DataInspector:
    """Auditor de qualidade de dados"""
    
    def __init__(self):
        self.data_dir = Path("data/processed")
        self.financials_path = self.data_dir / "cvm_financials_history.csv"
        self.prices_path = self.data_dir / "price_history.json"
        
        self.report = {
            'financials': {},
            'prices': {},
            'summary': {}
        }
    
    def inspect_financials(self):
        """Inspeciona dados fundamentalistas"""
        print("\n" + "="*80)
        print("üìä INSPECIONANDO CVM_FINANCIALS_HISTORY.CSV")
        print("="*80 + "\n")
        
        # Ler apenas colunas necess√°rias
        key_cols = ['ticker', 'date', 'p_l', 'p_vp', 'roe', 'roic', 'dy', 
                    'net_margin', 'net_debt_ebitda', 'revenue_cagr_5y']
        
        print("Carregando CSV (primeiros 5000 registros para an√°lise r√°pida)...")
        df = pd.read_csv(self.financials_path, usecols=lambda x: x in key_cols, 
                        parse_dates=['date'], low_memory=False, nrows=5000)
        
        print(f"Total de registros: {len(df)}")
        print(f"Colunas carregadas: {list(df.columns)}\n")
        
        # Validar colunas faltantes
        expected_cols = ['p_l', 'p_vp', 'roe', 'roic', 'dy', 'net_margin', 
                        'net_debt_ebitda', 'revenue_cagr_5y']
        missing_cols = [col for col in expected_cols if col not in df.columns]
        if missing_cols:
            print(f"‚ö†Ô∏è  Colunas faltantes: {missing_cols}\n")
        
        # Analisar por ticker (registro mais recente)
        df['date'] = pd.to_datetime(df['date'])
        latest_df = df.sort_values('date').groupby('ticker').last().reset_index()
        
        total_tickers = len(latest_df)
        print(f"Total de tickers √∫nicos: {total_tickers}\n")
        
        issues = defaultdict(list)
        
        for indicator in expected_cols:
            if indicator not in df.columns:
                continue
            
            # Dados faltantes (None/NaN)
            null_mask = latest_df[indicator].isnull()
            null_tickers = latest_df[null_mask]['ticker'].tolist()
            if null_tickers:
                issues[f'{indicator}_null'].extend(null_tickers)
            
            # Zero em indicadores que n√£o deveriam ser zero
            if indicator in ['p_l', 'p_vp', 'roe', 'roic']:
                zero_mask = latest_df[indicator] == 0
                zero_tickers = latest_df[zero_mask]['ticker'].tolist()
                if zero_tickers:
                    issues[f'{indicator}_zero'].extend(zero_tickers)
            
            # Negativos em indicadores positivos
            if indicator in ['p_l', 'p_vp', 'roe', 'roic', 'dy']:
                neg_mask = latest_df[indicator] < 0
                neg_tickers = latest_df[neg_mask]['ticker'].tolist()
                if neg_tickers:
                    issues[f'{indicator}_negative'].extend(neg_tickers)
        
        # Relat√≥rio
        print("üîç PROBLEMAS ENCONTRADOS:\n")
        
        critical_count = 0
        for issue_type in sorted(issues.keys()):
            tickers = issues[issue_type]
            count = len(tickers)
            if count > 0:
                pct = (count / total_tickers) * 100
                critical = issue_type in ['p_l_zero', 'p_l_null', 'roe_zero', 'roe_null']
                marker = "üö®" if critical else "‚ö†Ô∏è "
                
                print(f"{marker} {issue_type}: {count} tickers ({pct:.1f}%)")
                
                if critical:
                    critical_count += count
                    print(f"   Exemplos: {', '.join(tickers[:5])}")
        
        self.report['financials'] = {
            'total': total_tickers,
            'issues': {k: len(v) for k, v in issues.items()},
            'critical_count': critical_count,
            'critical_tickers': {
                'p_l_zero': issues.get('p_l_zero', [])[:20],
                'p_l_null': issues.get('p_l_null', [])[:20],
                'roe_zero': issues.get('roe_zero', [])[:20],
                'roe_null': issues.get('roe_null', [])[:20]
            }
        }
        
        return issues
    
    def inspect_prices(self):
        """Inspeciona hist√≥rico de pre√ßos"""
        print("\n" + "="*80)
        print("üìà INSPECIONANDO PRICE_HISTORY.JSON")
        print("="*80 + "\n")
        
        print("Carregando arquivo (pode demorar)...")
        with open(self.prices_path, 'r') as f:
            prices = json.load(f)
        
        total_tickers = len(prices)
        print(f"Total de tickers: {total_tickers}\n")
        
        issues = defaultdict(list)
        ticker_stats = {}
        
        for ticker, records in list(prices.items())[:100]:  # Sample primeiros 100
            if not records:
                issues['no_prices'].append(ticker)
                continue
            
            df = pd.DataFrame(records)
            df['date'] = pd.to_datetime(df['date'])
            df = df.sort_values('date')
            
            # Estat√≠sticas
            ticker_stats[ticker] = {
                'count': len(df),
                'first_date': df['date'].min().strftime('%Y-%m-%d'),
                'last_date': df['date'].max().strftime('%Y-%m-%d')
            }
            
            # Problema 1: Poucos dados
            if len(df) < 100:
                issues['insufficient_data'].append(ticker)
            
            # Problema 2: Gaps grandes (>30 dias)
            df['gap'] = df['date'].diff().dt.days
            max_gap = df['gap'].max()
            
            if max_gap > 30:
                issues['large_gaps'].append(ticker)
            
            # Problema 3: Dados muito antigos
            last_date = df['date'].max()
            if last_date < pd.to_datetime("2023-01-01"):
                issues['outdated'].append(ticker)
        
        # Relat√≥rio
        print("üîç PROBLEMAS ENCONTRADOS (Sample 100 tickers):\n")
        
        for issue_type in sorted(issues.keys()):
            tickers = issues[issue_type]
            count = len(tickers)
            if count > 0:
                print(f"‚ö†Ô∏è  {issue_type}: {count} tickers")
                print(f"   Exemplos: {', '.join(tickers[:5])}")
        
        self.report['prices'] = {
            'total': total_tickers,
            'sampled': 100,
            'issues': {k: len(v) for k, v in issues.items()},
            'sample_stats': list(ticker_stats.items())[:10]
        }
        
        return issues
    
    def create_report(self):
        """Gera relat√≥rio final"""
        print("\n" + "="*80)
        print("üìã RELAT√ìRIO DE QUALIDADE DE DADOS")
        print("="*80 + "\n")
        
        fin = self.report['financials']
        prc = self.report['prices']
        
        print(f"‚úÖ Financials: {fin['total']} tickers carregados")
        print(f"‚úÖ Prices: {prc['total']} tickers carregados\n")
        
        print(f"üö® PROBLEMAS CR√çTICOS (Financials):")
        print(f"   P/L inv√°lido: {fin['issues'].get('p_l_zero', 0) + fin['issues'].get('p_l_null', 0)} tickers")
        print(f"   ROE inv√°lido: {fin['issues'].get('roe_zero', 0) + fin['issues'].get('roe_null', 0)} tickers\n")
        
        # Salvar relat√≥rio detalhado
        report_path = "data_quality_report.json"
        with open(report_path, 'w') as f:
            json.dump(self.report, f, indent=2)
        
        print(f"üíæ Relat√≥rio completo salvo em: {report_path}\n")
        
        # Recomenda√ß√µes
        print("üîß A√á√ïES NECESS√ÅRIAS:")
        print("   1. ‚ùå REMOVER tickers com P/L=0 do universo de simula√ß√£o")
        print("   2. ‚ùå REMOVER tickers com ROE=0 do universo de simula√ß√£o")
        print("   3. ‚ö†Ô∏è  Considerar re-executar ETL para tickers com dados null")
        print("   4. ‚úÖ Adicionar filtros de qualidade no DataProvider\n")


if __name__ == "__main__":
    inspector = DataInspector()
    
    # Fase 1: Inspecionar Financials
    fin_issues = inspector.inspect_financials()
    
    # Fase 2: SKIP prices (arquivo muito grande - 180MB JSON)
    print("\n‚è© Pulando inspe√ß√£o de prices (arquivo 180MB)\n")
    inspector.report['prices'] = {'total': '?', 'skipped': True}
    
    # Fase 3: Relat√≥rio
    inspector.create_report()
